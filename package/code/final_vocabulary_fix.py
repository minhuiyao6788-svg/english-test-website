#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å½»åº•ä¿®å¤è¯æ±‡é¢˜é€‰é¡¹é‡å¤é—®é¢˜
ä¸ºæ‰€æœ‰æœ‰é—®é¢˜çš„è¯æ±‡é¢˜æä¾›å®Œå…¨ä¸åŒçš„4ä¸ªé€‰é¡¹
"""

import json

def final_vocabulary_fix():
    """å½»åº•ä¿®å¤è¯æ±‡é¢˜çš„é€‰é¡¹é‡å¤é—®é¢˜"""
    
    # è¯»å–å½“å‰æ•°æ®
    with open('/workspace/data/ielts_questions.json', 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # å®šä¹‰å®Œå…¨ä¸åŒçš„é€‰é¡¹
    final_corrections = {
        "voc_015": {
            "question": "The _____ of the research findings has implications for future studies.",
            "correct_word": "implications",
            "options": {
                "A": "implications",    # æ­£ç¡®ç­”æ¡ˆ
                "B": "interpretations", # è§£é‡Š
                "C": "applications",    # åº”ç”¨
                "D": "investigations"   # è°ƒæŸ¥
            },
            "explanation": "implicationsæ„ä¸º'å«ä¹‰ï¼Œå½±å“'ï¼ŒæŒ‡ç ”ç©¶å‘ç°çš„å«ä¹‰å¯¹æœªæ¥ç ”ç©¶æœ‰å½±å“ã€‚"
        },
        "voc_020": {
            "question": "The _____ of the research was published in a prestigious scientific journal.",
            "correct_word": "findings",
            "options": {
                "A": "findings",        # æ­£ç¡®ç­”æ¡ˆ
                "B": "conclusions",     # ç»“è®º
                "C": "discoveries",     # å‘ç°
                "D": "results"          # ç»“æœ
            },
            "explanation": "findingsæ„ä¸º'å‘ç°ï¼Œç ”ç©¶ç»“æœ'ï¼ŒæŒ‡ç ”ç©¶ç»“æœå‘è¡¨åœ¨æƒå¨ç§‘å­¦æœŸåˆŠä¸Šã€‚"
        },
        "voc_024": {
            "question": "The _____ of the student's progress has been excellent this semester.",
            "correct_word": "improvement",
            "options": {
                "A": "improvement",     # æ­£ç¡®ç­”æ¡ˆ
                "B": "advancement",     # è¿›æ­¥
                "C": "enhancement",     # å¢å¼º
                "D": "development"      # å‘å±•
            },
            "explanation": "improvementæ„ä¸º'è¿›æ­¥ï¼Œæ”¹å–„'ï¼ŒæŒ‡å­¦ç”Ÿè¿™å­¦æœŸçš„è¿›æ­¥éå¸¸å‡ºè‰²ã€‚"
        },
        "voc_028": {
            "question": "The _____ of the research data required sophisticated computer analysis.",
            "correct_word": "processing",
            "options": {
                "A": "processing",      # æ­£ç¡®ç­”æ¡ˆ
                "B": "analysis",        # åˆ†æ
                "C": "examination",     # æ£€æŸ¥
                "D": "evaluation"       # è¯„ä¼°
            },
            "explanation": "processingæ„ä¸º'å¤„ç†'ï¼ŒæŒ‡ç ”ç©¶æ•°æ®çš„å¤„ç†éœ€è¦å¤æ‚çš„è®¡ç®—æœºåˆ†æã€‚"
        },
        "voc_029": {
            "question": "The _____ of the conference attracted participants from around the world.",
            "correct_word": "prestige",
            "options": {
                "A": "prestige",        # æ­£ç¡®ç­”æ¡ˆ
                "B": "reputation",      # å£°èª‰
                "C": "status",          # åœ°ä½
                "D": "standing"         # å£°æœ›
            },
            "explanation": "prestigeæ„ä¸º'å£°æœ›ï¼Œå¨æœ›'ï¼ŒæŒ‡ä¼šè®®çš„å£°æœ›å¸å¼•äº†æ¥è‡ªä¸–ç•Œå„åœ°çš„å‚ä¸è€…ã€‚"
        }
    }
    
    # ä¿®å¤åŸºç¡€ç‰ˆå’Œå®Œæ•´ç‰ˆä¸­çš„è¯æ±‡é¢˜
    fix_count = 0
    for section in ['basic_version', 'complete_version']:
        if section in data:
            if 'vocabulary' in data[section] and 'questions' in data[section]['vocabulary']:
                for question in data[section]['vocabulary']['questions']:
                    question_id = question['id']
                    if question_id in final_corrections:
                        print(f"æœ€ç»ˆä¿®å¤é¢˜ç›® {question_id}: {question['question'][:50]}...")
                        question['options'] = final_corrections[question_id]['options']
                        question['explanation'] = final_corrections[question_id]['explanation']
                        print(f"  æœ€ç»ˆé€‰é¡¹: {list(question['options'].values())}")
                        fix_count += 1
    
    # ä¿å­˜ä¿®å¤åçš„æ•°æ®
    with open('/workspace/data/ielts_questions.json', 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… æœ€ç»ˆè¯æ±‡é¢˜é€‰é¡¹ä¿®å¤å®Œæˆï¼å…±ä¿®å¤ {fix_count} é“é¢˜")

def comprehensive_verify():
    """å…¨é¢éªŒè¯æ‰€æœ‰è¯æ±‡é¢˜"""
    
    with open('/workspace/data/ielts_questions.json', 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    problems = []
    correct_count = 0
    total_count = 0
    
    # æ£€æŸ¥åŸºç¡€ç‰ˆå’Œå®Œæ•´ç‰ˆ
    for section in ['basic_version', 'complete_version']:
        if section in data and 'vocabulary' in data[section] and 'questions' in data[section]['vocabulary']:
            for question in data[section]['vocabulary']['questions']:
                total_count += 1
                question_id = question['id']
                options = list(question['options'].values())
                
                # æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤é€‰é¡¹
                unique_options = set(options)
                if len(unique_options) < 4:
                    problems.append({
                        'id': question_id,
                        'options': options,
                        'unique_count': len(unique_options)
                    })
                else:
                    correct_count += 1
    
    print(f"\n=== å…¨é¢è¯æ±‡é¢˜é€‰é¡¹éªŒè¯ç»“æœ ===")
    print(f"æ€»è¯æ±‡é¢˜æ•°: {total_count}")
    print(f"æ­£ç¡®é¢˜æ•°: {correct_count}")
    print(f"æœ‰é—®é¢˜é¢˜æ•°: {len(problems)}")
    
    if problems:
        print(f"\nä»æœ‰é—®é¢˜çš„é¢˜ç›®:")
        for problem in problems:
            print(f"  {problem['id']}: é€‰é¡¹ {problem['options']} (å”¯ä¸€é€‰é¡¹æ•°: {problem['unique_count']})")
    else:
        print(f"\nğŸ‰ æ‰€æœ‰è¯æ±‡é¢˜éƒ½æœ‰4ä¸ªå®Œå…¨ä¸åŒçš„é€‰é¡¹ï¼")
    
    return len(problems) == 0

if __name__ == "__main__":
    print("å¼€å§‹æœ€ç»ˆä¿®å¤è¯æ±‡é¢˜é€‰é¡¹é‡å¤é—®é¢˜...")
    final_vocabulary_fix()
    print("\nè¿›è¡Œæœ€ç»ˆéªŒè¯...")
    comprehensive_verify()